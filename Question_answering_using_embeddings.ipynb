{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4ca8276-e829-4cff-8905-47534e4b4d4e",
      "metadata": {
        "id": "c4ca8276-e829-4cff-8905-47534e4b4d4e"
      },
      "source": [
        "# Question Answering using Embeddings\n",
        "\n",
        "Many use cases require GPT-3 to respond to user questions with insightful answers. For example, a customer support chatbot may need to provide answers to common questions. The GPT models have picked up a lot of general knowledge in training, but we often need to ingest and use a large library of more specific information.\n",
        "\n",
        "In this notebook we will demonstrate a method for enabling GPT-3 to answer questions using a library of text as a reference, by using document embeddings and retrieval. We'll be using a dataset of Wikipedia articles about the 2020 Summer Olympic Games. Please see [this notebook](fine-tuned_qa/olympics-1-collect-data.ipynb) to follow the data gathering process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9e3839a6-9146-4f60-b74b-19abbc24278d",
      "metadata": {
        "id": "9e3839a6-9146-4f60-b74b-19abbc24278d",
        "outputId": "2fedfc12-338f-44f8-cca9-4e4aaddae94d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=ce23ce2ca355d930cbe5a3e9890d180068fb1fbf3d0e906eda9f770a84e4af00\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "gaJOWxFebz-V",
        "outputId": "3c0ae2e4-c256-4386-a56b-7bea02ede791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "id": "gaJOWxFebz-V",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blobfile>=2\n",
            "  Downloading blobfile-2.0.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.8/dist-packages (from tiktoken) (2022.6.2)\n",
            "Collecting requests>=2.26.0\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.25.3\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex~=3.8\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.8/dist-packages (from blobfile>=2->tiktoken) (4.9.2)\n",
            "Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.8/dist-packages (from blobfile>=2->tiktoken) (3.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->tiktoken) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->tiktoken) (2.10)\n",
            "Installing collected packages: urllib3, pycryptodomex, requests, blobfile, tiktoken\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed blobfile-2.0.1 pycryptodomex-3.17 requests-2.28.2 tiktoken-0.2.0 urllib3-1.26.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install python 3.9\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9"
      ],
      "metadata": {
        "id": "T4Ht4OS4hs_5",
        "outputId": "43a4cbe2-9853-4c45-f2b2-6d6868bb57f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T4Ht4OS4hs_5",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Connecting to security.ubuntu.com] [Waiting for headers] [Waiting for heade\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [2 InRelease 15.6 kB/114 kB 14%] [Connecting to security.ubuntu.com] [Waitin\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "\r0% [4 InRelease 11.3 kB/108 kB 10%] [Connecting to security.ubuntu.com (185.125\r0% [Connecting to security.ubuntu.com (185.125.190.39)] [Waiting for headers] [\r                                                                               \rGet:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [5 InRelease 14.2 kB/18.1 kB 78%\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,970 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,386 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,131 kB]\n",
            "Fetched 6,844 kB in 2s (3,031 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib python3.9-minimal\n",
            "Suggested packages:\n",
            "  python3.9-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib python3.9 python3.9-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 5,023 kB of archives.\n",
            "After this operation, 19.7 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.9-minimal amd64 3.9.16-1+focal1 [804 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.9-minimal amd64 3.9.16-1+focal1 [2,062 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.9-stdlib amd64 3.9.16-1+focal1 [1,662 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.9 amd64 3.9.16-1+focal1 [495 kB]\n",
            "Fetched 5,023 kB in 2s (2,098 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 128126 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.9-minimal_3.9.16-1+focal1_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.16-1+focal1) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../python3.9-minimal_3.9.16-1+focal1_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.16-1+focal1) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.9-stdlib_3.9.16-1+focal1_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.16-1+focal1) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../python3.9_3.9.16-1+focal1_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.16-1+focal1) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.16-1+focal1) ...\n",
            "Setting up python3.9-minimal (3.9.16-1+focal1) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.16-1+focal1) ...\n",
            "Setting up python3.9 (3.9.16-1+focal1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "!python --version"
      ],
      "metadata": {
        "id": "EWkJvXcVh206",
        "outputId": "c4ef0334-e381-476d-fc51-55782e0e6a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EWkJvXcVh206",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.9.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import openai\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tiktoken\n",
        "\n",
        "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\""
      ],
      "metadata": {
        "id": "fFGMMmp6bhl7"
      },
      "id": "fFGMMmp6bhl7",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "4UfG07PIfK8b"
      },
      "id": "4UfG07PIfK8b",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9312f62f-e208-4030-a648-71ad97aee74f",
      "metadata": {
        "id": "9312f62f-e208-4030-a648-71ad97aee74f"
      },
      "source": [
        "By default, GPT-3 isn't an expert on the 2020 Olympics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a167516c-7c19-4bda-afa5-031aa0ae13bb",
      "metadata": {
        "id": "a167516c-7c19-4bda-afa5-031aa0ae13bb",
        "outputId": "9bb90139-16e9-4cbb-e641-ca90722dcd9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Marcelo Chierighini of Brazil won the gold medal in the men's high jump at the 2020 Summer Olympics.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "prompt = \"Who won the 2020 Summer Olympics men's high jump?\"\n",
        "\n",
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FNjSrsn1csm1",
        "outputId": "882a8529-888c-4b98-c585-dc147265cce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FNjSrsn1csm1",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47204cce-a7d5-4c81-ab6e-53323026e08c",
      "metadata": {
        "id": "47204cce-a7d5-4c81-ab6e-53323026e08c"
      },
      "source": [
        "Marcelo is a gold medalist swimmer, and, we assume, not much of a high jumper! Evidently GPT-3 needs some assistance here. \n",
        "\n",
        "The first issue to tackle is that the model is hallucinating an answer rather than telling us \"I don't know\". This is bad because it makes it hard to trust the answer that the model gives us! \n",
        "\n",
        "# 0) Preventing hallucination with prompt engineering\n",
        "\n",
        "We can address this hallucination issue by being more explicit with our prompt:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a5451371-17fe-4ef3-aa02-affcf4edb0e0",
      "metadata": {
        "id": "a5451371-17fe-4ef3-aa02-affcf4edb0e0",
        "outputId": "1acadf3f-a8db-4559-ab16-67b91e7a7592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sorry, I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
        "\n",
        "Q: Who won the 2020 Summer Olympics men's high jump?\n",
        "A:\"\"\"\n",
        "\n",
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af18d66-d47a-496d-ae5f-4c5d53caa434",
      "metadata": {
        "id": "1af18d66-d47a-496d-ae5f-4c5d53caa434"
      },
      "source": [
        "To help the model answer the question, we provide extra contextual information in the prompt. When the total required context is short, we can include it in the prompt directly. For example we can use this information taken from Wikipedia. We update the initial prompt to tell the model to explicitly make use of the provided text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fceaf665-2602-4788-bc44-9eb256a6f955",
      "metadata": {
        "id": "fceaf665-2602-4788-bc44-9eb256a6f955",
        "outputId": "09bbdcb4-dc27-4b5c-b9d5-19bbacba1c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Gianmarco Tamberi and Mutaz Essa Barshim emerged as joint winners of the event.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
        "\n",
        "Context:\n",
        "The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
        "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
        "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
        "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
        "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
        "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
        "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
        "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
        "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
        "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg\n",
        "of Sweden (1984 to 1992).\n",
        "\n",
        "Q: Who won the 2020 Summer Olympics men's high jump?\n",
        "A:\"\"\"\n",
        "\n",
        "openai.Completion.create(\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    model=COMPLETIONS_MODEL\n",
        ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee85ee77-d8d2-4788-b57e-0785f2d7e2e3",
      "metadata": {
        "id": "ee85ee77-d8d2-4788-b57e-0785f2d7e2e3"
      },
      "source": [
        "Adding extra information into the prompt only works when the dataset of extra content that the model may need to know is small enough to fit in a single prompt. What do we do when we need the model to choose relevant contextual information from within a large body of information?\n",
        "\n",
        "**In the remainder of this notebook, we will demonstrate a method for augmenting GPT-3 with a large body of additional contextual information by using document embeddings and retrieval.** This method answers queries in two steps: first it retrieves the information relevant to the query, then it writes an answer tailored to the question based on the retrieved information. The first step uses the [Embeddings API](https://beta.openai.com/docs/guides/embeddings), the second step uses the [Completions API](https://beta.openai.com/docs/guides/completion/introduction).\n",
        " \n",
        "The steps are:\n",
        "* Preprocess the contextual information by splitting it into chunks and create an embedding vector for each chunk.\n",
        "* On receiving a query, embed the query in the same vector space as the context chunks and find the context embeddings which are most similar to the query.\n",
        "* Prepend the most relevant context embeddings to the query prompt.\n",
        "* Submit the question along with the most relevant context to GPT, and receive an answer which makes use of the provided contextual information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c9bfea5-a028-4191-b9f1-f210d76ec4e3",
      "metadata": {
        "id": "0c9bfea5-a028-4191-b9f1-f210d76ec4e3"
      },
      "source": [
        "# 1) Preprocess the document library\n",
        "\n",
        "We plan to use document embeddings to fetch the most relevant part of parts of our document library and insert them into the prompt that we provide to GPT-3. We therefore need to break up the document library into \"sections\" of context, which can be searched and retrieved separately. \n",
        "\n",
        "Sections should be large enough to contain enough information to answer a question; but small enough to fit one or several into the GPT-3 prompt. We find that approximately a paragraph of text is usually a good length, but you should experiment for your particular use case. In this example, Wikipedia articles are already grouped into semantically related headers, so we will use these to define our sections. This preprocessing has already been done in [this notebook](fine-tuned_qa/olympics-1-collect-data.ipynb), so we will load the results and use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cc9c8d69-e234-48b4-87e3-935970e1523a",
      "metadata": {
        "id": "cc9c8d69-e234-48b4-87e3-935970e1523a",
        "outputId": "abbd0fbe-a541-4f21-bf6e-75bc003d1d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3964 rows in the data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                 content  \\\n",
              "title                                              heading                                                                 \n",
              "Bahrain at the 2020 Summer Olympics                Shooting            Bahrain entered one shooter at the games, afte...   \n",
              "Azerbaijan at the 2020 Summer Olympics             Shooting            Azerbaijani shooters achieved quota places for...   \n",
              "Equestrian at the 2020 Summer Olympics             Dressage            Teams are made of three athletes, all of whom ...   \n",
              "Colombia at the 2020 Summer Olympics               Judo                Colombia qualified one judoka for the women's ...   \n",
              "Canoeing at the 2020 Summer Olympics – Men's K-... Competition format  Sprint canoeing uses a four-round format for e...   \n",
              "\n",
              "                                                                       tokens  \n",
              "title                                              heading                     \n",
              "Bahrain at the 2020 Summer Olympics                Shooting                44  \n",
              "Azerbaijan at the 2020 Summer Olympics             Shooting                69  \n",
              "Equestrian at the 2020 Summer Olympics             Dressage               399  \n",
              "Colombia at the 2020 Summer Olympics               Judo                    88  \n",
              "Canoeing at the 2020 Summer Olympics – Men's K-... Competition format     157  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-935ddf5d-b8dd-4505-a0bc-1e5793d9b3b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <th>heading</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bahrain at the 2020 Summer Olympics</th>\n",
              "      <th>Shooting</th>\n",
              "      <td>Bahrain entered one shooter at the games, afte...</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Azerbaijan at the 2020 Summer Olympics</th>\n",
              "      <th>Shooting</th>\n",
              "      <td>Azerbaijani shooters achieved quota places for...</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Equestrian at the 2020 Summer Olympics</th>\n",
              "      <th>Dressage</th>\n",
              "      <td>Teams are made of three athletes, all of whom ...</td>\n",
              "      <td>399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Colombia at the 2020 Summer Olympics</th>\n",
              "      <th>Judo</th>\n",
              "      <td>Colombia qualified one judoka for the women's ...</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Canoeing at the 2020 Summer Olympics – Men's K-1 1000 metres</th>\n",
              "      <th>Competition format</th>\n",
              "      <td>Sprint canoeing uses a four-round format for e...</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-935ddf5d-b8dd-4505-a0bc-1e5793d9b3b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-935ddf5d-b8dd-4505-a0bc-1e5793d9b3b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-935ddf5d-b8dd-4505-a0bc-1e5793d9b3b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# We have hosted the processed dataset, so you can download it directly without having to recreate it.\n",
        "# This dataset has already been split into sections, one row for each section of the Wikipedia page.\n",
        "\n",
        "df = pd.read_csv('https://cdn.openai.com/API/examples/data/olympics_sections_text.csv')\n",
        "df = df.set_index([\"title\", \"heading\"])\n",
        "print(f\"{len(df)} rows in the data.\")\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17b88b9-7ea2-491e-9727-12617c74a77d",
      "metadata": {
        "id": "a17b88b9-7ea2-491e-9727-12617c74a77d"
      },
      "source": [
        "We preprocess the document sections by creating an embedding vector for each section. An embedding is a vector of numbers that helps us understand how semantically similar or different the texts are. The closer two embeddings are to each other, the more similar are their contents. See the [documentation on OpenAI embeddings](https://beta.openai.com/docs/guides/embeddings) for more information.\n",
        "\n",
        "This indexing stage can be executed offline and only runs once to precompute the indexes for the dataset so that each piece of content can be retrieved later. Since this is a small example, we will store and search the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/) or [Weaviate](https://github.com/semi-technologies/weaviate) to power the search."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "vKCaWMtMhY1S",
        "outputId": "2941fee4-2c47-4952-c568-cc44c3ae1387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vKCaWMtMhY1S",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
        "    result = openai.Embedding.create(\n",
        "      model=model,\n",
        "      input=text\n",
        "    )\n",
        "    return result[\"data\"][0][\"embedding\"]\n",
        "\n",
        "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
        "    \"\"\"\n",
        "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
        "    \n",
        "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
        "    }"
      ],
      "metadata": {
        "id": "-VJzXaRFg76z",
        "outputId": "ca654117-5bb4-450e-b3d7-c8a706285f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "id": "-VJzXaRFg76z",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-966a87f9b990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_MODEL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     result = openai.Embedding.create(\n\u001b[1;32m      3\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ba475f30-ef7f-431c-b60d-d5970b62ad09",
      "metadata": {
        "id": "ba475f30-ef7f-431c-b60d-d5970b62ad09",
        "outputId": "640486a3-90b6-4c8d-926e-681b76392570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-966a87f9b990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_MODEL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     result = openai.Embedding.create(\n\u001b[1;32m      3\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
        "    result = openai.Embedding.create(\n",
        "      model=model,\n",
        "      input=text\n",
        "    )\n",
        "    return result[\"data\"][0][\"embedding\"]\n",
        "\n",
        "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
        "    \"\"\"\n",
        "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
        "    \n",
        "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737266aa-cbe7-4691-87c1-fce8a31632f1",
      "metadata": {
        "id": "737266aa-cbe7-4691-87c1-fce8a31632f1"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
        "    \"\"\"\n",
        "    Read the document embeddings and their keys from a CSV.\n",
        "    \n",
        "    fname is the path to a CSV with exactly these named columns: \n",
        "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
        "    \"\"\"\n",
        "    \n",
        "    df = pd.read_csv(fname, header=0)\n",
        "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
        "    return {\n",
        "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe9c723-f838-4c75-8ed8-286b2e491a60",
      "metadata": {
        "id": "cfe9c723-f838-4c75-8ed8-286b2e491a60"
      },
      "source": [
        "Again, we have hosted the embeddings for you so you don't have to re-calculate them from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab50bfca-cb02-41c6-b338-4400abe1d86e",
      "metadata": {
        "id": "ab50bfca-cb02-41c6-b338-4400abe1d86e"
      },
      "outputs": [],
      "source": [
        "document_embeddings = load_embeddings(\"https://cdn.openai.com/API/examples/data/olympics_sections_document_embeddings.csv\")\n",
        "\n",
        "# ===== OR, uncomment the below line to recaculate the embeddings from scratch. ========\n",
        "\n",
        "# document_embeddings = compute_doc_embeddings(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a8c713-c8a9-47dc-85a4-871ee1395566",
      "metadata": {
        "id": "b9a8c713-c8a9-47dc-85a4-871ee1395566",
        "outputId": "c281b92a-a46b-4b98-904d-99ecbfb1a85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('2020 Summer Olympics', 'Summary') : [0.0037565305829048, -0.0061981128528714, -0.0087078781798481, -0.0071364338509738, -0.0025227521546185]... (1536 entries)\n"
          ]
        }
      ],
      "source": [
        "# An example embedding:\n",
        "example_entry = list(document_embeddings.items())[0]\n",
        "print(f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa32cf88-9edb-4dc6-b4cf-a16a8de7d304",
      "metadata": {
        "tags": [],
        "id": "aa32cf88-9edb-4dc6-b4cf-a16a8de7d304"
      },
      "source": [
        "So we have split our document library into sections, and encoded them by creating embedding vectors that represent each chunk. Next we will use these embeddings to answer our users' questions.\n",
        "\n",
        "# 2) Find the most similar document embeddings to the question embedding\n",
        "\n",
        "At the time of question-answering, to answer the user's query we compute the query embedding of the question and use it to find the most similar document sections. Since this is a small example, we store and search the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/) or [Weaviate](https://github.com/semi-technologies/weaviate) to power the search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcd680e9-f194-4180-b14f-fc357498eb92",
      "metadata": {
        "id": "dcd680e9-f194-4180-b14f-fc357498eb92"
      },
      "outputs": [],
      "source": [
        "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
        "    \"\"\"\n",
        "    Returns the similarity between two vectors.\n",
        "    \n",
        "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
        "    \"\"\"\n",
        "    return np.dot(np.array(x), np.array(y))\n",
        "\n",
        "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
        "    \"\"\"\n",
        "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
        "    to find the most relevant sections. \n",
        "    \n",
        "    Return the list of document sections, sorted by relevance in descending order.\n",
        "    \"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "    \n",
        "    document_similarities = sorted([\n",
        "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
        "    ], reverse=True)\n",
        "    \n",
        "    return document_similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a27d73-f47f-480d-b336-079414f749cb",
      "metadata": {
        "id": "e3a27d73-f47f-480d-b336-079414f749cb",
        "outputId": "c238c961-4468-4af5-f6de-4041e26b3f34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.884864308450606,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')),\n",
              " (0.8633938355935518,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's pole vault\", 'Summary')),\n",
              " (0.861639730583851,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')),\n",
              " (0.8560523857031264,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's triple jump\", 'Summary')),\n",
              " (0.8469039130441247,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Men's 110 metres hurdles\",\n",
              "   'Summary'))]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "order_document_sections_by_query_similarity(\"Who won the men's high jump?\", document_embeddings)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "729c2ce7-8540-4ab2-bb3a-76c4dfcb689c",
      "metadata": {
        "id": "729c2ce7-8540-4ab2-bb3a-76c4dfcb689c",
        "outputId": "5ecadb7b-a79c-4dd6-d3cb-3ad1d27abc14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.8726165220223294,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Women's long jump\", 'Summary')),\n",
              " (0.8682196158313358,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Women's high jump\", 'Summary')),\n",
              " (0.863191526370672,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Women's pole vault\", 'Summary')),\n",
              " (0.8609374262115406,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Women's triple jump\", 'Summary')),\n",
              " (0.8581515607285688,\n",
              "  (\"Athletics at the 2020 Summer Olympics – Women's 100 metres hurdles\",\n",
              "   'Summary'))]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "order_document_sections_by_query_similarity(\"Who won the women's high jump?\", document_embeddings)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf71fae-abb1-46b2-a483-c1b2f1a915c2",
      "metadata": {
        "id": "3cf71fae-abb1-46b2-a483-c1b2f1a915c2"
      },
      "source": [
        "We can see that the most relevant document sections for each question include the summaries for the Men's and Women's high jump competitions - which is exactly what we would expect."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0efa0f6-4469-457a-89a4-a2f5736a01e0",
      "metadata": {
        "id": "a0efa0f6-4469-457a-89a4-a2f5736a01e0"
      },
      "source": [
        "# 3) Add the most relevant document sections to the query prompt\n",
        "\n",
        "Once we've calculated the most relevant pieces of context, we construct a prompt by simply prepending them to the supplied query. It is helpful to use a query separator to help the model distinguish between separate pieces of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b763ace2-1946-48e0-8ff1-91ba335d47a0",
      "metadata": {
        "id": "b763ace2-1946-48e0-8ff1-91ba335d47a0",
        "outputId": "4afcb559-9a97-48dc-9da4-94105070027c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Context separator contains 3 tokens'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_SECTION_LEN = 500\n",
        "SEPARATOR = \"\\n* \"\n",
        "ENCODING = \"gpt2\"  # encoding for text-davinci-003\n",
        "\n",
        "encoding = tiktoken.get_encoding(ENCODING)\n",
        "separator_len = len(encoding.encode(SEPARATOR))\n",
        "\n",
        "f\"Context separator contains {separator_len} tokens\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c5c0509-eeb9-4552-a5d4-6ace04ef73dd",
      "metadata": {
        "id": "0c5c0509-eeb9-4552-a5d4-6ace04ef73dd"
      },
      "outputs": [],
      "source": [
        "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Fetch relevant \n",
        "    \"\"\"\n",
        "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
        "    \n",
        "    chosen_sections = []\n",
        "    chosen_sections_len = 0\n",
        "    chosen_sections_indexes = []\n",
        "     \n",
        "    for _, section_index in most_relevant_document_sections:\n",
        "        # Add contexts until we run out of space.        \n",
        "        document_section = df.loc[section_index]\n",
        "        \n",
        "        chosen_sections_len += document_section.tokens + separator_len\n",
        "        if chosen_sections_len > MAX_SECTION_LEN:\n",
        "            break\n",
        "            \n",
        "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
        "        chosen_sections_indexes.append(str(section_index))\n",
        "            \n",
        "    # Useful diagnostic information\n",
        "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
        "    print(\"\\n\".join(chosen_sections_indexes))\n",
        "    \n",
        "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
        "    \n",
        "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f614045a-3917-4b28-9643-7e0c299ec1a7",
      "metadata": {
        "id": "f614045a-3917-4b28-9643-7e0c299ec1a7",
        "outputId": "a232efca-b72c-44be-9eed-bc23c3d0fbae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')\n",
            "===\n",
            " Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\n",
            "\n",
            "Context:\n",
            "\n",
            "* The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium. 33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021). Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance where the athletes of different nations had agreed to share the same medal in the history of Olympics. Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a 'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg of Sweden (1984 to 1992).\n",
            "* The men's long jump event at the 2020 Summer Olympics took place between 31 July and 2 August 2021 at the Japan National Stadium. Approximately 35 athletes were expected to compete; the exact number was dependent on how many nations use universality places to enter athletes in addition to the 32 qualifying through time or ranking (1 universality place was used in 2016). 31 athletes from 20 nations competed. Miltiadis Tentoglou won the gold medal, Greece's first medal in the men's long jump. Cuban athletes Juan Miguel Echevarría and Maykel Massó earned silver and bronze, respectively, the nation's first medals in the event since 2008.\n",
            "\n",
            " Q: Who won the 2020 Summer Olympics men's high jump?\n",
            " A:\n"
          ]
        }
      ],
      "source": [
        "prompt = construct_prompt(\n",
        "    \"Who won the 2020 Summer Olympics men's high jump?\",\n",
        "    document_embeddings,\n",
        "    df\n",
        ")\n",
        "\n",
        "print(\"===\\n\", prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b022fd4-0a3c-4ae1-bed1-4c80e4f0fb56",
      "metadata": {
        "tags": [],
        "id": "1b022fd4-0a3c-4ae1-bed1-4c80e4f0fb56"
      },
      "source": [
        "We have now obtained the document sections that are most relevant to the question. As a final step, let's put it all together to get an answer to the question.\n",
        "\n",
        "# 4) Answer the user's question based on the context.\n",
        "\n",
        "Now that we've retrieved the relevant context and constructed our prompt, we can finally use the Completions API to answer the user's query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0edfec7-9243-4573-92e0-253d31c771ad",
      "metadata": {
        "id": "b0edfec7-9243-4573-92e0-253d31c771ad"
      },
      "outputs": [],
      "source": [
        "COMPLETIONS_API_PARAMS = {\n",
        "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
        "    \"temperature\": 0.0,\n",
        "    \"max_tokens\": 300,\n",
        "    \"model\": COMPLETIONS_MODEL,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1c9a69-848e-4099-a90d-c8da36c153d5",
      "metadata": {
        "id": "9c1c9a69-848e-4099-a90d-c8da36c153d5"
      },
      "outputs": [],
      "source": [
        "def answer_query_with_context(\n",
        "    query: str,\n",
        "    df: pd.DataFrame,\n",
        "    document_embeddings: dict[(str, str), np.array],\n",
        "    show_prompt: bool = False\n",
        ") -> str:\n",
        "    prompt = construct_prompt(\n",
        "        query,\n",
        "        document_embeddings,\n",
        "        df\n",
        "    )\n",
        "    \n",
        "    if show_prompt:\n",
        "        print(prompt)\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "                prompt=prompt,\n",
        "                **COMPLETIONS_API_PARAMS\n",
        "            )\n",
        "\n",
        "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c233e449-bf33-4c9e-b095-6a4dd278c8fd",
      "metadata": {
        "id": "c233e449-bf33-4c9e-b095-6a4dd278c8fd",
        "outputId": "9fe7cce0-5e86-410a-d3bd-a2a6bc5ab7b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's high jump\", 'Summary')\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's long jump\", 'Summary')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Gianmarco Tamberi and Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer_query_with_context(\"Who won the 2020 Summer Olympics men's high jump?\", df, document_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b48d155-d2d4-447c-ab8e-5a5b4722b07c",
      "metadata": {
        "id": "7b48d155-d2d4-447c-ab8e-5a5b4722b07c"
      },
      "source": [
        "By combining the Embeddings and Completions APIs, we have created a question-answering model which can answer questions using a large base of additional knowledge. It also understands when it doesn't know the answer! \n",
        "\n",
        "For this example we have used a dataset of Wikipedia articles, but that dataset could be replaced with books, articles, documentation, service manuals, or much much more. **We can't wait to see what you create with GPT-3!**\n",
        "\n",
        "# More Examples\n",
        "\n",
        "Let's have some fun and try some more examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1127867b-2884-44bb-9439-0e8ae171c835",
      "metadata": {
        "id": "1127867b-2884-44bb-9439-0e8ae171c835",
        "outputId": "bc175c0c-1b46-4c07-cf7c-806572f896e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 1 document sections:\n",
            "('Concerns and controversies at the 2020 Summer Olympics', 'Summary')\n",
            "\n",
            "Q: Why was the 2020 Summer Olympics originally postponed?\n",
            "A: The 2020 Summer Olympics were originally postponed due to the COVID-19 pandemic.\n"
          ]
        }
      ],
      "source": [
        "query = \"Why was the 2020 Summer Olympics originally postponed?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "720d9e0b-b189-4101-91ee-babf736199e6",
      "metadata": {
        "id": "720d9e0b-b189-4101-91ee-babf736199e6",
        "outputId": "34128bbd-472a-48c1-caa0-a64eb81c9e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2 document sections:\n",
            "('2020 Summer Olympics medal table', 'Summary')\n",
            "('List of 2020 Summer Olympics medal winners', 'Summary')\n",
            "\n",
            "Q: In the 2020 Summer Olympics, how many gold medals did the country which won the most medals win?\n",
            "A: The United States won the most medals overall, with 113, and the most gold medals, with 39.\n"
          ]
        }
      ],
      "source": [
        "query = \"In the 2020 Summer Olympics, how many gold medals did the country which won the most medals win?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8e51cc-e4eb-4557-9e09-2929d4df5b7f",
      "metadata": {
        "id": "4e8e51cc-e4eb-4557-9e09-2929d4df5b7f",
        "outputId": "6870d3b9-96ee-49bb-bbf8-855c96166fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's shot put\", 'Summary')\n",
            "(\"Athletics at the 2020 Summer Olympics – Men's discus throw\", 'Summary')\n",
            "\n",
            "Q: What was unusual about the men’s shotput competition?\n",
            "A: The same three competitors received the same medals in back-to-back editions of the same individual event.\n"
          ]
        }
      ],
      "source": [
        "query = \"What was unusual about the men’s shotput competition?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c83519-e3c6-4c44-8b4a-98cbb3a5f5ba",
      "metadata": {
        "id": "37c83519-e3c6-4c44-8b4a-98cbb3a5f5ba",
        "outputId": "3845769a-22f9-4a39-943c-e6475b61f31e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2 document sections:\n",
            "('Italy at the 2020 Summer Olympics', 'Summary')\n",
            "('San Marino at the 2020 Summer Olympics', 'Summary')\n",
            "\n",
            "Q: In the 2020 Summer Olympics, how many silver medals did Italy win?\n",
            "A: 10 silver medals.\n"
          ]
        }
      ],
      "source": [
        "query = \"In the 2020 Summer Olympics, how many silver medals did Italy win?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "177c945e-f5c4-4fa5-8331-44f328b25e44",
      "metadata": {
        "id": "177c945e-f5c4-4fa5-8331-44f328b25e44"
      },
      "source": [
        "Our Q&A model is less prone to hallucinating answers, and has a better sense of what it does or doesn't know. This works when the information isn't contained in the context; when the question is nonsensical; or when the question is theoretically answerable but beyond GPT-3's powers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a1a9ef-e1ee-4f80-a1b1-6164ccfa5bac",
      "metadata": {
        "id": "26a1a9ef-e1ee-4f80-a1b1-6164ccfa5bac",
        "outputId": "6fb65b35-4d34-4259-a4d4-3977e721984b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 4 document sections:\n",
            "('France at the 2020 Summer Olympics', 'Taekwondo')\n",
            "('Taekwondo at the 2020 Summer Olympics – Qualification', 'Qualification summary')\n",
            "('2020 Summer Olympics medal table', 'Medal count')\n",
            "(\"Taekwondo at the 2020 Summer Olympics – Men's 80 kg\", 'Competition format')\n",
            "\n",
            "Q: What is the total number of medals won by France, multiplied by the number of Taekwondo medals given out to all countries?\n",
            "A: I don't know.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the total number of medals won by France, multiplied by the number of Taekwondo medals given out to all countries?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fba8a63-eb81-4661-ae17-59bb5e2933d6",
      "metadata": {
        "id": "9fba8a63-eb81-4661-ae17-59bb5e2933d6",
        "outputId": "d4423336-ba30-4602-c9b2-5de4c5650cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 3 document sections:\n",
            "(\"Sport climbing at the 2020 Summer Olympics – Men's combined\", 'Route-setting')\n",
            "(\"Ski mountaineering at the 2020 Winter Youth Olympics – Boys' individual\", 'Summary')\n",
            "(\"Ski mountaineering at the 2020 Winter Youth Olympics – Girls' individual\", 'Summary')\n",
            "\n",
            "Q: What is the tallest mountain in the world?\n",
            "A: I don't know.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the tallest mountain in the world?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4c693b-cdb9-4f4c-bd1b-f77b29097a1f",
      "metadata": {
        "id": "2d4c693b-cdb9-4f4c-bd1b-f77b29097a1f",
        "outputId": "2e2d8081-73ef-49ff-fe79-ea0cde69e4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 2 document sections:\n",
            "(\"Gymnastics at the 2020 Summer Olympics – Women's trampoline\", 'Summary')\n",
            "('Equestrian at the 2020 Summer Olympics – Team jumping', 'Summary')\n",
            "\n",
            "Q: Who won the grimblesplatch competition at the 2020 Summer Olympic games?\n",
            "A: I don't know.\n"
          ]
        }
      ],
      "source": [
        "query = \"Who won the grimblesplatch competition at the 2020 Summer Olympic games?\"\n",
        "answer = answer_query_with_context(query, df, document_embeddings)\n",
        "\n",
        "print(f\"\\nQ: {query}\\nA: {answer}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.9 ('openai')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}